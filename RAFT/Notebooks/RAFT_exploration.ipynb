{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7P01YDMU3o7"
      },
      "source": [
        "# **RAFT Starter**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hs1LlfOFhzoJ"
      },
      "source": [
        "## RAFT Models\n",
        "\n",
        "RAFT has several pretrained models:\n",
        " - raft-chairs - trained on FlyingChairs\n",
        " - raft-things - trained on FlyingChairs + FlyingThings\n",
        " - raft-sintel - trained on FlyingChairs + FlyingThings + Sintel + KITTI\n",
        " - raft-kitti - raft-sintel finetuned on only KITTI\n",
        " - raft-small - trained on FlyingChairs + FlyingThings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnrUTdBFcByn"
      },
      "source": [
        "Clone the repo and import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4xqoAUSUy3S",
        "outputId": "a0eaf61a-dcae-44ba-9d57-259db1b1db61"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/princeton-vl/RAFT.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pwd\n",
        "!cd RAFT\n",
        "!git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHUJ3bE7cH-j"
      },
      "outputs": [],
      "source": [
        "# necessary imports\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "\n",
        "import torch                     # for all things PyTorch\n",
        "import torch.nn as nn            # for torch.nn.Module, the parent object for PyTorch models\n",
        "import torch.nn.functional as F  # for the activation function\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print gpu info\n",
        "\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.get_arch_list())\n",
        " \n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA is available!\")\n",
        "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
        "    for i in range(torch.cuda.device_count()):\n",
        "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
        "        print(f\"Allocated memory: {torch.cuda.memory_allocated(i)/1024**2:.2f} MB\")\n",
        "        print(f\"Cached memory: {torch.cuda.memory_reserved(i)/1024**2:.2f} MB\")\n",
        "        print(f\"Properties: {torch.cuda.get_device_properties(i)}\")\n",
        "else:\n",
        "    print(\"CUDA is not available.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auoba8E2fs2b"
      },
      "source": [
        "Add RAFT core to path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJQfY_UUfb0a"
      },
      "outputs": [],
      "source": [
        "# Add RAFT core to path\n",
        "\n",
        "sys.path.append('RAFT/core')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6v76U_xxckIs"
      },
      "source": [
        "Get demo frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get sintel demo frames\n",
        "\n",
        "demo_path = 'RAFT/demo-frames'\n",
        "frame1 = cv2.imread(os.path.join(demo_path, 'frame_0020.png'))\n",
        "frame2 = cv2.imread(os.path.join(demo_path, 'frame_0021.png'))\n",
        "frame3 = cv2.imread(os.path.join(demo_path, 'frame_0023.png'))\n",
        "\n",
        "frame1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2RGB)\n",
        "frame2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2RGB)\n",
        "frame3 = cv2.cvtColor(frame3, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "_, ax = plt.subplots(1, 3, figsize=(15, 8))\n",
        "ax[0].imshow(frame1)\n",
        "ax[1].imshow(frame2)\n",
        "ax[2].imshow(frame3);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMdU8UuRd4P7"
      },
      "source": [
        "## Download models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEGKBvgEc0qd",
        "outputId": "558279ef-694f-41e6-80f4-b1fcdeebfa8c"
      },
      "outputs": [],
      "source": [
        "%cd RAFT\n",
        "!./download_models.sh\n",
        "# !python demo.py --model=models/raft-things.pth --path=demo-frames\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqpa4YLAfCd1"
      },
      "source": [
        "### Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uinuMz76e2Jb"
      },
      "outputs": [],
      "source": [
        "from collections import OrderedDict\n",
        "from raft import RAFT\n",
        "from utils import flow_viz\n",
        "from utils.utils import InputPadder\n",
        "\n",
        "\n",
        "# convert to torch and get correct dimensions\n",
        "def process_img(img, device):\n",
        "    return torch.from_numpy(img).permute(2, 0, 1).float()[None].to(device)\n",
        "\n",
        "\n",
        "def load_model(weights_path, args):\n",
        "    model = RAFT(args)\n",
        "    \n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"current device is\")\n",
        "    print(device)\n",
        "\n",
        "    try:\n",
        "        pretrained_weights = torch.load(weights_path, map_location=device)\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Fehler beim laden der Gewichte: {e}\")\n",
        "\n",
        "    print(torch.cuda.device_count())\n",
        "\n",
        "    if torch.cuda.device_count() >= 1:\n",
        "       model = torch.nn.DataParallel(model)\n",
        "    \n",
        "    try:\n",
        "        model.load_state_dict(pretrained_weights)\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Fehler beim setzen der Gewichte: {e}\")\n",
        "    \n",
        "    model.to(device)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# perform inference with every model\n",
        "def inference(model, frame1, frame2, device, pad_mode='sintel', iters=12, flow_init=None, upsample=True, test_mode=True):\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # preprocess\n",
        "        frame1 = process_img(frame1, device)\n",
        "        frame2 = process_img(frame2, device)\n",
        "\n",
        "        # important because raft requires every image to be divisible by 8\n",
        "        padder = InputPadder(frame1.shape, mode=pad_mode)\n",
        "        frame1, frame2 = padder.pad(frame1, frame2)\n",
        "\n",
        "        # predict flow in two different modes\n",
        "        if test_mode:\n",
        "          # returns the initial flow (1/8 res) + upsampled flow (upsampled res)\n",
        "          flow_low, flow_up = model(frame1,\n",
        "                                    frame2,\n",
        "                                    iters=iters,\n",
        "                                    flow_init=flow_init,\n",
        "                                    upsample=upsample,\n",
        "                                    test_mode=test_mode)\n",
        "\n",
        "          return flow_low, flow_up\n",
        "\n",
        "        else:\n",
        "            # we get all flow it. for the specified amount of iterations\n",
        "            flow_iters = model(frame1,\n",
        "                               frame2,\n",
        "                               iters=iters,\n",
        "                               flow_init=flow_init,\n",
        "                               upsample=upsample,\n",
        "                               test_mode=test_mode)\n",
        "            \n",
        "            return flow_iters\n",
        "\n",
        "\n",
        "def get_viz(flo):\n",
        "    flo = flo[0].permute(1,2,0).cpu().numpy()\n",
        "    return flow_viz.flow_to_image(flo)\n",
        "\n",
        "\n",
        "# sketchy class to pass to RAFT\n",
        "class Args():\n",
        "  def __init__(self, model='', path='', small=False, mixed_precision=True, alternate_corr=False):\n",
        "    self.model = model\n",
        "    self.path = path\n",
        "    self.small = small\n",
        "    self.mixed_precision = mixed_precision\n",
        "    self.alternate_corr = alternate_corr\n",
        "\n",
        "  \"\"\" Sketchy hack to pretend to iterate through the class objects \"\"\"\n",
        "  def __iter__(self):\n",
        "    return self\n",
        "\n",
        "  def __next__(self):\n",
        "    raise StopIteration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1JwL5zWj4OK"
      },
      "source": [
        "### Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9u0-jW3lXuE"
      },
      "outputs": [],
      "source": [
        "# load the \".pth\" model\n",
        "\n",
        "model = load_model(\"RAFT/models/raft-sintel.pth\", args=Args())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltJKTkOmofsH"
      },
      "source": [
        "### Predict Optical Flow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-62nC-abj6o5",
        "outputId": "7844ec03-ee26-434b-ee6f-e0466a26b7b1"
      },
      "outputs": [],
      "source": [
        "# run the model with test mode\n",
        "\n",
        "# flow_low = 1/8 res\n",
        "# flow_up = full res\n",
        "\n",
        "flow_low, flow_up = inference(model, frame1, frame2, device='cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpKrGmOhpmRm",
        "outputId": "adb13566-28ee-4d4b-8157-2b0d434b6cf2"
      },
      "outputs": [],
      "source": [
        "# display output shapes\n",
        "\n",
        "print(\"flow_low shape = \" + str(flow_low.shape))\n",
        "print(\"flow_low shape = \" + str(flow_up.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLI4p64PoiOx"
      },
      "source": [
        "### Display Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "T7DnQ86sfYxR",
        "outputId": "167c7b59-d74a-4fa4-9e6c-3a906bf5a2f0"
      },
      "outputs": [],
      "source": [
        "# display the upsampled flow\n",
        "\n",
        "flow_low_viz = get_viz(flow_low)\n",
        "flow_up_viz = get_viz(flow_up)\n",
        "\n",
        "f, (ax0, ax1) = plt.subplots(1,2, figsize=(15,10))\n",
        "\n",
        "ax0.imshow(frame1)\n",
        "ax1.imshow(flow_up_viz)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "6vM12H1ZgpQ8",
        "outputId": "3e515572-45b3-4ad3-a1a7-638b090092e6"
      },
      "outputs": [],
      "source": [
        "# display the low res and upsampled flow\n",
        "\n",
        "f, (ax0, ax1) = plt.subplots(1,2, figsize=(15,10))\n",
        "\n",
        "ax0.imshow(flow_low_viz)\n",
        "ax0.set_title('1/8 res flow')\n",
        "ax1.imshow(flow_up_viz)\n",
        "ax1.set_title('convex upsampled flow');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "427ijNG5ooZe"
      },
      "outputs": [],
      "source": [
        "# run the model with saving all iterations\n",
        "\n",
        "flow_iters = inference(model, frame1, frame2, device='cuda', iters=20, test_mode=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "y-D4qfsvwXMN",
        "outputId": "197d93fa-92ff-4d16-fa1c-e41d1ce381bf"
      },
      "outputs": [],
      "source": [
        "# visualize first and final flow iteration\n",
        "\n",
        "f, (ax0, ax1) = plt.subplots(1,2, figsize=(20,10))\n",
        "\n",
        "ax0.imshow(get_viz(flow_iters[0]))\n",
        "ax0.set_title('first flow iteration')\n",
        "ax1.imshow(get_viz(flow_iters[-1]))\n",
        "ax1.set_title('final flow iteration');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kt6-R8sjqIPL"
      },
      "source": [
        "Save flow iters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kf15O1AVoGt2"
      },
      "outputs": [],
      "source": [
        "for i in range(0, len(flow_iters)):\n",
        "    # cv2.imwrite(f\"flow_iter_{i}.png\", get_viz(flow_iters[i]))\n",
        "    fig = plt.figure(figsize=(20, 10))\n",
        "    plt.imshow(get_viz(flow_iters[i]))\n",
        "    plt.title(f\"Iteration {i}\")\n",
        "    # fig.savefig(f\"flow_iter_{i}.png\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Flow estimation on a custom pair of frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# estimation on a custom pair of frames\n",
        "\n",
        "demo_path = '/home/max/Dokumente/CV_projectsFork/RAFT/custom_demo_frames'\n",
        "frame1 = cv2.imread(os.path.join(demo_path, 'm_baseFrameGray.jpg'))\n",
        "frame2 = cv2.imread(os.path.join(demo_path, 'm_nextFrameGray.jpg'))\n",
        "\n",
        "frame1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2RGB)\n",
        "frame2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "_, ax = plt.subplots(1, 2, figsize=(15, 8))\n",
        "ax[0].imshow(frame1)\n",
        "ax[1].imshow(frame2);\n",
        "\n",
        "## OPTIONAL (use KITTI only model)\n",
        "# del model\n",
        "# model = load_model(\"RAFT/models/raft-kitti.pth\", args=Args())\n",
        "# flow_iters = inference(model, frame1, frame2, device='cuda', pad_mode='kitti', iters=20, test_mode=False)\n",
        "# flow_iters = inference(model, frame1, frame2, device='cuda', pad_mode='kitti', iters=10, test_mode=False)\n",
        "flow_iters = inference(model, frame1, frame2, device='cuda', pad_mode='kitti', iters=9, test_mode=False)\n",
        "# flow_iters = inference(model, frame1, frame2, device='cuda', pad_mode='kitti', iters=5, test_mode=False)\n",
        "\n",
        "f, (ax0, ax1) = plt.subplots(1,2, figsize=(15,10))\n",
        "\n",
        "ax0.imshow(get_viz(flow_iters[0]))\n",
        "ax0.set_title('first flow iteration')\n",
        "ax1.imshow(get_viz(flow_iters[-1]))\n",
        "ax1.set_title('final flow iteration');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OA6Be6uh_Ua"
      },
      "source": [
        "## Estimate Flow with a Warm Start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwx_O9m8iDOi"
      },
      "outputs": [],
      "source": [
        "# get previous estimate at 1/8 res\n",
        "flow_lo, flow_up = inference(model, frame1, frame2, device='cuda', pad_mode=None, iters=20, test_mode=True)\n",
        "\n",
        "# 0 initialization\n",
        "flow_lo_cold, flow_up_cold = inference(model, frame2, frame3, device='cuda', pad_mode=None, flow_init=None, iters=20, test_mode=True)\n",
        "\n",
        "# warm initialization\n",
        "flow_lo_warm, flow_up_warm = inference(model, frame2, frame3, device='cuda', pad_mode=None, flow_init=flow_lo, iters=20, test_mode=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "LvEBVK7ejTRg",
        "outputId": "a3bc3a52-d55a-4513-c7e9-36cedc108940"
      },
      "outputs": [],
      "source": [
        "f, (ax0, ax1) = plt.subplots(1,2, figsize=(20,10))\n",
        "\n",
        "ax0.imshow(get_viz(flow_up_cold))\n",
        "ax0.set_title('0 initialized flow')\n",
        "ax1.imshow(get_viz(flow_up_warm))\n",
        "ax1.set_title('warm initialized flow');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Try an example on Kitti\n",
        "\n",
        "We can either use the KITTI website to download, or select a video sequence from the MOT challenge."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !wget https://s3.eu-central-1.amazonaws.com/avg-kitti/raw_data/2011_09_29_drive_0071/2011_09_29_drive_0071_sync.zip\n",
        "# !jar xf 2011_09_29_drive_0071_sync.zip\n",
        "\n",
        "!unzip 2011_09_29_drive_0071_sync.zip -d ./"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !wget https://motchallenge.net/sequenceVideos/KITTI-16-raw.webm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute Flow on a video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# cap = cv2.VideoCapture(\"KITTI-16-raw.webm\")\n",
        "\n",
        "# if (cap.isOpened() == False):\n",
        "#     print(\"Error opening video file\")\n",
        "\n",
        "# fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "# raw_frames = []\n",
        "# flows = []\n",
        "# flow_lo = None\n",
        "# i = 0\n",
        "# while(cap.isOpened()):\n",
        "\n",
        "#     # read each video frame\n",
        "#     ret, frame = cap.read()\n",
        "\n",
        "#     if ret == True:\n",
        "\n",
        "#         # save to list\n",
        "#         raw_frames.append(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "#         # compute flow\n",
        "#         flow_lo, flow_up = inference(model, frame2, frame3, device='cuda', flow_init=flow_lo, iters=20, test_mode=True)\n",
        "\n",
        "#         flows.append(flow_up)\n",
        "\n",
        "#         # increment counter\n",
        "#         i += 1\n",
        "\n",
        "#     # Break if nothing is returned\n",
        "#     else:\n",
        "#         break\n",
        "\n",
        "# # clean up\n",
        "# cap.release()\n",
        "# cv2.destroyAllWindows()\n",
        "# del cap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Flow example on a pair of frames\n",
        "\n",
        "Let's see how well RAFT does on a single pair of frames from the KITTI driving scene"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# nehme alle bilder\n",
        "\n",
        "from glob import glob\n",
        "\n",
        "left_image_paths = sorted(glob('/home/max/Dokumente/CV_projects/RAFT/2011_09_29/2011_09_29_drive_0071_sync/image_02/data/*.png'))\n",
        "frames = [cv2.imread(path) for path in left_image_paths]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# zuf√§lliger index\n",
        "\n",
        "idx = 75\n",
        "frame1 = frames[idx]\n",
        "frame2 = frames[idx + 1]\n",
        "frame3 = frames[idx + 2]\n",
        "\n",
        "frame1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2RGB)\n",
        "frame2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2RGB)\n",
        "frame3 = cv2.cvtColor(frame3, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "_, ax = plt.subplots(1, 2, figsize=(20, 8))\n",
        "ax[0].imshow(frame1)\n",
        "ax[1].imshow(frame2);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## OPTIONAL (use KITTI only model)\n",
        "# del model\n",
        "# model = load_model(\"RAFT/models/raft-kitti.pth\", args=Args())\n",
        "flow_iters = inference(model, frame1, frame2, device='cuda', pad_mode='kitti', iters=20, test_mode=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "f, (ax0, ax1) = plt.subplots(1,2, figsize=(20,10))\n",
        "\n",
        "ax0.imshow(get_viz(flow_iters[0]))\n",
        "ax0.set_title('first flow iteration')\n",
        "ax1.imshow(get_viz(flow_iters[-1]))\n",
        "ax1.set_title('final flow iteration');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Perform warm start flow prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "flow_lo, flow_up = inference(model, frame1, frame2, device='cuda', pad_mode='kitti', iters=20, test_mode=True)\n",
        "\n",
        "\n",
        "# from scratch\n",
        "flow_lo_cold, flow_up_cold = inference(model, frame2, frame3, device='cuda', pad_mode='kitti', flow_init=None, iters=20, test_mode=True)\n",
        "\n",
        "# passing 1/8 sampled flow\n",
        "flow_lo_warm, flow_up_warm = inference(model, frame2, frame3, device='cuda', pad_mode='kitti', flow_init=flow_lo, iters=20, test_mode=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "f, (ax0, ax1) = plt.subplots(1,2, figsize=(30,10))\n",
        "\n",
        "ax0.imshow(get_viz(flow_up_cold))\n",
        "ax0.set_title('0 initialized flow')\n",
        "ax1.imshow(get_viz(flow_up_warm))\n",
        "ax1.set_title('warm initialized flow');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAkbSiBnSfP-"
      },
      "source": [
        "# **Make a GIF of the fan video**\n",
        "\n",
        "In this section, we will estimate the flow of each frame using a warm start. In the previous estimations there is a lot of noise in the background of the fan. We will need to remove this noise in order to get good estimations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxSqJk0QSn5S"
      },
      "source": [
        "Get warm-start flow estimates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAiTy0bCSipP"
      },
      "outputs": [],
      "source": [
        "# store results\n",
        "unfiltered_flow_frames = []\n",
        "\n",
        "for i in range(2, len(frame_paths)):\n",
        "    # get frames\n",
        "    frame_1 = cv2.cvtColor(cv2.imread(frame_paths[i-2]), cv2.COLOR_BGR2RGB)\n",
        "    frame_2 = cv2.cvtColor(cv2.imread(frame_paths[i-1]), cv2.COLOR_BGR2RGB)\n",
        "    frame_3 = cv2.cvtColor(cv2.imread(frame_paths[i]), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # get previous estimate at 1/8 res\n",
        "    flow_lo, flow_up = inference(model, frame_1, frame_2, device='cuda', pad_mode=None, iters=20, test_mode=True)\n",
        "\n",
        "    # 0 initialization\n",
        "    flow_lo_cold, flow_up_cold = inference(model, frame_2, frame_3, device='cuda', pad_mode=None, flow_init=None, iters=20, test_mode=True)\n",
        "\n",
        "    # warm initialization\n",
        "    flow_lo_warm, flow_up_warm = inference(model, frame_2, frame_3, device='cuda', pad_mode=None, flow_init=flow_lo, iters=20, test_mode=True)\n",
        "\n",
        "    # save results\n",
        "    if i == 2:\n",
        "      unfiltered_flow_frames.append(flow_up)\n",
        "\n",
        "    unfiltered_flow_frames.append(flow_up_warm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xk2eNqF8Optn"
      },
      "source": [
        "Display results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "kzYV3H2MOrMM",
        "outputId": "ad2b0fb7-3f69-4d5c-dbf4-7ea35c7482f7"
      },
      "outputs": [],
      "source": [
        "idx = 0\n",
        "\n",
        "warm = unfiltered_flow_frames[idx].clone()\n",
        "warm[torch.abs(warm) < 2] = 0\n",
        "\n",
        "og_frame = cv2.cvtColor(cv2.imread(frame_paths[idx]), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "f, ax = plt.subplots(1, 2, figsize=(20,10))\n",
        "\n",
        "ax[0].imshow(og_frame)\n",
        "ax[0].set_title('Original frame')\n",
        "ax[1].imshow(get_viz(warm))\n",
        "ax[1].set_title('Optical Flow from Unfiltered frames');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDKFsNoaQXec"
      },
      "source": [
        "## **Second Attempt with Filtered Frames**\n",
        "\n",
        "Now we will show how some basic filtering can make a big difference for flow estimation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6B2h837dGjy"
      },
      "source": [
        "Code to filter image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vthC08ODdFvc"
      },
      "outputs": [],
      "source": [
        "def filter_image(frame, iters=1):\n",
        "\n",
        "    filtered = frame.copy()\n",
        "\n",
        "    for i in range(iters):\n",
        "      filtered = cv2.GaussianBlur(filtered, dst=None, ksize=(3,3), sigmaX=3)\n",
        "      filtered = cv2.Laplacian(filtered, dst=None, ddepth=-1, ksize=1, scale=7, delta=1)\n",
        "      filtered = cv2.GaussianBlur(filtered, dst=None, ksize=(5,5), sigmaX=5)\n",
        "      filtered[filtered < 10] = 0\n",
        "      filtered = cv2.convertScaleAbs(filtered, dst=None, alpha=10, beta=0)\n",
        "\n",
        "    return filtered"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-zhzMfbTJMb"
      },
      "outputs": [],
      "source": [
        "# store results\n",
        "cold_flow_frames = []\n",
        "flow_frames = []\n",
        "\n",
        "for i in range(2, len(frame_paths)):\n",
        "    # get frames\n",
        "    frame_1 = cv2.cvtColor(cv2.imread(frame_paths[i-2]), cv2.COLOR_BGR2GRAY)\n",
        "    frame_2 = cv2.cvtColor(cv2.imread(frame_paths[i-1]), cv2.COLOR_BGR2GRAY)\n",
        "    frame_3 = cv2.cvtColor(cv2.imread(frame_paths[i]), cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Filter\n",
        "    frame_1 = filter_image(frame_1, iters=2)\n",
        "    frame_2 = filter_image(frame_2, iters=2)\n",
        "    frame_3 = filter_image(frame_3, iters=2)\n",
        "\n",
        "    # repeat last 3 dimensions\n",
        "    frame_1 = np.repeat(frame_1[:, :, None], 3, axis=-1)\n",
        "    frame_2 = np.repeat(frame_2[:, :, None], 3, axis=-1)\n",
        "    frame_3 = np.repeat(frame_3[:, :, None], 3, axis=-1)\n",
        "\n",
        "    # get previous estimate at 1/8 res\n",
        "    flow_lo, flow_up = inference(model, frame_1, frame_2, device='cuda', pad_mode=None, iters=20, test_mode=True)\n",
        "\n",
        "    # 0 initialization\n",
        "    flow_lo_cold, flow_up_cold = inference(model, frame_2, frame_3, device='cuda', pad_mode=None, flow_init=None, iters=20, test_mode=True)\n",
        "\n",
        "    # warm initialization\n",
        "    flow_lo_warm, flow_up_warm = inference(model, frame_2, frame_3, device='cuda', pad_mode=None, flow_init=flow_lo, iters=20, test_mode=True)\n",
        "\n",
        "    # save results\n",
        "    if i == 2:\n",
        "      flow_frames.append(flow_up)\n",
        "      cold_flow_frames.append(flow_up)\n",
        "\n",
        "    flow_frames.append(flow_up_warm)\n",
        "    cold_flow_frames.append(flow_up_cold)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-VGxZzZbn64"
      },
      "source": [
        "### Check and filter results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "rHkMaiQ_kfjH",
        "outputId": "79cf11ad-6884-449c-e6df-d6b41adf39db"
      },
      "outputs": [],
      "source": [
        "# filter results\n",
        "\n",
        "idx = 0\n",
        "cold = cold_flow_frames[idx].clone()\n",
        "cold[torch.abs(cold) < 2] = 0\n",
        "\n",
        "warm = flow_frames[idx].clone()\n",
        "warm[torch.abs(warm) < 2] = 0\n",
        "\n",
        "og_frame = cv2.cvtColor(cv2.imread(frame_paths[idx]), cv2.COLOR_BGR2RGB)\n",
        "frame = cv2.cvtColor(og_frame, cv2.COLOR_RGB2GRAY)\n",
        "frame = filter_image(frame)\n",
        "frame = filter_image(frame)\n",
        "\n",
        "f, ax = plt.subplots(1, 3, figsize=(20,10))\n",
        "\n",
        "ax[0].imshow(frame)\n",
        "ax[0].set_title('Filtered frame')\n",
        "ax[1].imshow(get_viz(cold))\n",
        "ax[1].set_title('0 initialized flow')\n",
        "ax[2].imshow(get_viz(warm))\n",
        "ax[2].set_title('warm initialized flow');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLDpatY8Q8al"
      },
      "source": [
        "### Display everything"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r81BZ2E0Rni8",
        "outputId": "b74c7b1f-8de2-4734-c9dd-7cb32c825585"
      },
      "outputs": [],
      "source": [
        "len(frame_paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kixl9nY7Rpgq",
        "outputId": "725c22d8-df26-4b3c-8f04-aee85df175b4"
      },
      "outputs": [],
      "source": [
        "len(unfiltered_flow_frames), len(flow_frames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        },
        "id": "WC28OaYRLUCw",
        "outputId": "5b6ccebf-008b-44bd-8012-5fff79cec0b0"
      },
      "outputs": [],
      "source": [
        "idx = 70\n",
        "thresh = 2\n",
        "\n",
        "un_flow = unfiltered_flow_frames[idx].clone()\n",
        "un_flow[torch.abs(un_flow) < thresh] = 0\n",
        "\n",
        "flow = flow_frames[idx + 1].clone()\n",
        "flow[torch.abs(flow) < thresh] = 0\n",
        "\n",
        "og_frame = cv2.cvtColor(cv2.imread(frame_paths[idx]), cv2.COLOR_BGR2RGB)\n",
        "frame = cv2.cvtColor(og_frame, cv2.COLOR_RGB2GRAY)\n",
        "frame = filter_image(frame)\n",
        "frame = filter_image(frame)\n",
        "\n",
        "fig, ax = plt.subplots(2, 2, figsize=(20, 10))\n",
        "\n",
        "ax[0, 0].imshow(og_frame)\n",
        "ax[0, 0].set_title('Original frame')\n",
        "ax[0, 0].axis(False)\n",
        "\n",
        "ax[0, 1].imshow(frame)\n",
        "ax[0, 1].set_title('Filtered frame')\n",
        "ax[0, 1].axis(False)\n",
        "\n",
        "ax[1, 0].imshow(get_viz(un_flow))\n",
        "ax[1, 0].set_title('Unfiltered Optical Flow');\n",
        "ax[1, 0].axis(False);\n",
        "\n",
        "ax[1, 1].imshow(get_viz(flow))\n",
        "ax[1, 1].set_title('Filtered Optical Flow');\n",
        "ax[1, 1].axis(False);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMmA5YT2e7b5"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from glob import glob\n",
        "\n",
        "\n",
        "def create_gif_from_images(save_path, image_path, ext):\n",
        "    ''' creates a GIF from a folder of images\n",
        "        Inputs:\n",
        "            save_path (str) - path to save GIF\n",
        "            image_path (str) - path where images are located\n",
        "            ext (str) - extension of the images\n",
        "        Outputs:\n",
        "            None\n",
        "\n",
        "        Update:\n",
        "            Add functionality for multiple extensions\n",
        "    '''\n",
        "    image_paths = sorted(glob(os.path.join(image_path, f'*.{ext}')))\n",
        "\n",
        "    pil_images = [Image.open(im_path ) for im_path in image_paths]\n",
        "\n",
        "    pil_images[0].save(save_path, format='GIF', append_images=pil_images,\n",
        "                      save_all=True, duration=50, loop=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBG1mc3yMOPf"
      },
      "outputs": [],
      "source": [
        "thresh = 2\n",
        "\n",
        "\n",
        "for i in range(len(flow_frames) - 1):\n",
        "\n",
        "  un_flow = unfiltered_flow_frames[i].clone()\n",
        "  un_flow[torch.abs(un_flow) < thresh] = 0\n",
        "\n",
        "  flow = flow_frames[i + 1].clone()\n",
        "  flow[torch.abs(flow) < thresh] = 0\n",
        "\n",
        "  og_frame = cv2.cvtColor(cv2.imread(frame_paths[i]), cv2.COLOR_BGR2RGB)\n",
        "  frame = cv2.cvtColor(og_frame, cv2.COLOR_RGB2GRAY)\n",
        "  frame = filter_image(frame)\n",
        "  frame = filter_image(frame)\n",
        "\n",
        "  fig, ax = plt.subplots(2, 2, figsize=(20, 10))\n",
        "\n",
        "  ax[0, 0].imshow(og_frame)\n",
        "  ax[0, 0].set_title('Original frame')\n",
        "  ax[0, 0].axis(False)\n",
        "\n",
        "  ax[0, 1].imshow(frame)\n",
        "  ax[0, 1].set_title('Filtered frame')\n",
        "  ax[0, 1].axis(False)\n",
        "\n",
        "  ax[1, 0].imshow(get_viz(un_flow))\n",
        "  ax[1, 0].set_title('Unfiltered Optical Flow');\n",
        "  ax[1, 0].axis(False);\n",
        "\n",
        "  ax[1, 1].imshow(get_viz(flow))\n",
        "  ax[1, 1].set_title('Filtered Optical Flow');\n",
        "  ax[1, 1].axis(False);\n",
        "\n",
        "  fig.savefig(f\"flow_gif_{i}.jpg\");\n",
        "  plt.close();\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6YU8I3eBUyx-"
      },
      "outputs": [],
      "source": [
        "gif_frame_paths = sorted(glob('*.jpg'))\n",
        "gif_frame_paths.sort(key=lambda f: int(''.join(filter(str.isdigit, f))))\n",
        "gif_path = 'flow.gif'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdjQWtJwU71n"
      },
      "outputs": [],
      "source": [
        "pil_images = [Image.open(im_path) for im_path in gif_frame_paths]\n",
        "pil_images[0].save(gif_path, format='GIF', append_images=pil_images,\n",
        "                      save_all=True, duration=50, loop=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mmvYyV0VHcg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
