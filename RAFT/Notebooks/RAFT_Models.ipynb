{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAFT Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAFT Models\n",
    "\n",
    "RAFT has several pretrained models:\n",
    " - raft-chairs - trained on FlyingChairs\n",
    " - raft-things - trained on FlyingChairs + FlyingThings\n",
    " - raft-sintel - trained on FlyingChairs + FlyingThings + Sintel + KITTI\n",
    " - raft-kitti - raft-sintel finetuned on only KITTI\n",
    " - raft-small - trained on FlyingChairs + FlyingThings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clone the repo\n",
    "\n",
    "!pwd\n",
    "!cd RAFT\n",
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary imports\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "import torch                     # for all things PyTorch\n",
    "import torch.nn as nn            # for torch.nn.Module, the parent object for PyTorch models\n",
    "import torch.nn.functional as F  # for the activation function\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print gpu info\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.get_arch_list())\n",
    " \n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        print(f\"Allocated memory: {torch.cuda.memory_allocated(i)/1024**2:.2f} MB\")\n",
    "        print(f\"Cached memory: {torch.cuda.memory_reserved(i)/1024**2:.2f} MB\")\n",
    "        print(f\"Properties: {torch.cuda.get_device_properties(i)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add RAFT core to path\n",
    "\n",
    "# sys.path.append('RAFT/core')\n",
    "sys.path.append('/home/max/Dokumente/Vitis-AI/CV_projects/RAFT/RAFT/core')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from raft import RAFT\n",
    "from utils import flow_viz\n",
    "from utils.utils import InputPadder\n",
    "\n",
    "\n",
    "# convert to torch and get correct dimensions\n",
    "def process_img(img, device):\n",
    "    print(\"[process_img] entering\")\n",
    "    return torch.from_numpy(img).permute(2, 0, 1).float()[None].to(device)\n",
    "\n",
    "def load_model(weights_path, args):\n",
    "    print(\"[load_model] entering\")\n",
    "\n",
    "    model = RAFT(args)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"[load_model] current device is: \" + str(device))\n",
    "\n",
    "    try:\n",
    "        pretrained_weights = torch.load(weights_path, map_location=device)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"[load_model] Fehler beim laden der Gewichte: {e}\")\n",
    "\n",
    "    print(\"[load_model] device_count(): \" + str(torch.cuda.device_count()))\n",
    "\n",
    "    if torch.cuda.device_count() >= 1:\n",
    "       model = torch.nn.DataParallel(model)\n",
    "    \n",
    "    try:\n",
    "        model.load_state_dict(pretrained_weights)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"[load_model] Fehler beim setzen der Gewichte: {e}\")\n",
    "    \n",
    "    model.to(device)\n",
    "\n",
    "    return model\n",
    "\n",
    "# perform inference with every model\n",
    "def inference(model, frame1, frame2, device, pad_mode='sintel', iters=12, flow_init=None, upsample=True, test_mode=True):\n",
    "    print(\"[inference] entering\")\n",
    "\n",
    "    # entering evel mode: specific operstions like batch-norm. and dropout are deactivated\n",
    "    model.eval()\n",
    "    \n",
    "    # do not calc or store gradients: increase performance\n",
    "    with torch.no_grad():\n",
    "        # preprocess\n",
    "        frame1 = process_img(frame1, device)\n",
    "        frame2 = process_img(frame2, device)\n",
    "\n",
    "        # important because raft requires every image to be divisible by 8\n",
    "        padder = InputPadder(frame1.shape, mode=pad_mode)\n",
    "        frame1, frame2 = padder.pad(frame1, frame2)\n",
    "\n",
    "        print(\"[inference] Upsampled = \" + str(upsample))\n",
    "\n",
    "        # predict flow in two different modes\n",
    "        if test_mode:\n",
    "            # returns the initial flow (1/8 res) + upsampled flow (upsampled res)\n",
    "            flow_low, flow_up = model(frame1, frame2, iters=iters, flow_init=flow_init, upsample=upsample, test_mode=test_mode)\n",
    "            \n",
    "            return flow_low, flow_up\n",
    "\n",
    "        else:\n",
    "            # we get all flow it. for the specified amount of iterations\n",
    "            flow_iters = model(frame1, frame2, iters=iters, flow_init=flow_init, upsample=upsample, test_mode=test_mode)\n",
    "            \n",
    "            return flow_iters\n",
    "\n",
    "def get_viz(flo):\n",
    "    print(\"[get_viz] entering\")\n",
    "    flo = flo[0].permute(1,2,0).cpu().numpy()\n",
    "    return flow_viz.flow_to_image(flo)\n",
    "\n",
    "def print_model_info(model):\n",
    "    print(\"[print_model_info] Model architecture:\")\n",
    "    print(model)\n",
    "\n",
    "    print(\"\\n [print_model_info] Model parameters and their shapes:\")\n",
    "    for name, param in model.named_parameters():\n",
    "        print(f\"{name}: {param.shape}\")\n",
    "\n",
    "def inspect_model(model):\n",
    "    print(\"[inspect_model] entering\")\n",
    "\n",
    "    # print(\"Model Architecture:\\n\")\n",
    "    # print(model)\n",
    "    \n",
    "    # Gesamtanzahl der Parameter berechnen\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print( \"[inspect_model] Total number of parameters: \" + str(total_params) )\n",
    "\n",
    "    frame1 = cv2.imread(\"/home/max/Dokumente/CV_projects/RAFT/custom_demo_frames/m_baseFrameGray.jpg\")\n",
    "    frame2 = cv2.imread(\"/home/max/Dokumente/CV_projects/RAFT/custom_demo_frames/m_nextFrameGray.jpg\")\n",
    "\n",
    "    frame1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2RGB)\n",
    "    frame2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # entering evel mode: specific operstions like batch-norm. and dropout are deactivated\n",
    "    model.eval()\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"[inspect_model] current device is: \" + str(device))\n",
    "\n",
    "    # do not calc or store gradients: increase performance\n",
    "    with torch.no_grad():\n",
    "        # preprocess\n",
    "        frame1 = process_img(frame1, device)\n",
    "        frame2 = process_img(frame2, device)\n",
    "\n",
    "        # important because raft requires every image to be divisible by 8\n",
    "        padder = InputPadder(frame1.shape, mode='sintel')\n",
    "\n",
    "        frame1, frame2 = padder.pad(frame1, frame2)\n",
    "\n",
    "        # predict flow: returns the initial flow (1/8 res) + upsampled flow (upsampled res)\n",
    "        flow_low, flow_up = model(frame1, frame2, iters=12, flow_init=None, upsample=True, test_mode=True)\n",
    "\n",
    "    \n",
    "    # print(\"[inspect_model] Output of flow_low: \")\n",
    "    # print(flow_low)\n",
    "\n",
    "    # print(\"[inspect_model] Output of flow_up: \")\n",
    "    # print(flow_up)\n",
    "\n",
    "    # Modellzusammenfassung manuell erstellen\n",
    "    print(\"[inspect_model] Model Summary: \")\n",
    "    for name, param in model.named_parameters():\n",
    "        print(f\"{name}: {param.numel()} parameters\")\n",
    "    \n",
    "    print( \"[inspect_model] Total number of parameters: \" + str(total_params) )\n",
    "\n",
    "    return model\n",
    "\n",
    "# sketchy class to pass to RAFT\n",
    "class Args():\n",
    "  def __init__(self, model='', path='', small=False, mixed_precision=True, alternate_corr=False):\n",
    "    self.model = model\n",
    "    self.path = path\n",
    "    self.small = small\n",
    "    self.mixed_precision = mixed_precision\n",
    "    self.alternate_corr = alternate_corr\n",
    "\n",
    "# Sketchy hack to pretend to iterate through the class objects\n",
    "  def __iter__(self):\n",
    "    return self\n",
    "\n",
    "  def __next__(self):\n",
    "    raise StopIteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd RAFT\n",
    "\n",
    "!chmod +x download_models.sh\n",
    "!./download_models.sh\n",
    "# !python demo.py --model=models/raft-things.pth --path=demo-frames\n",
    "\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the \".pth\" model\n",
    "\n",
    "model = load_model(\"RAFT/models/raft-sintel.pth\", args=Args())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untersuchen der Modellstruktur\n",
    "\n",
    "model = load_model(\"RAFT/models/raft-sintel.pth\", args=Args())\n",
    "\n",
    "print_model_info(model)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispielaufruf der Funktion\n",
    "model_path = \"/home/max/Dokumente/CV_projects/RAFT/RAFT/models/raft-sintel.pth\"\n",
    "args=Args()\n",
    "\n",
    "model = load_model(model_path, args)\n",
    "model = inspect_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a own model and inspect it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------------\n",
    "# Modell definieren und speichern\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define model\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 50)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(50, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model and optimizer\n",
    "model = SimpleModel()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Generate dummy input\n",
    "dummy_input = torch.randn(10)\n",
    "\n",
    "# Save the model and optimizer state\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict()\n",
    "}, '/home/max/Dokumente/CV_projects/RAFT/simple_model.pth')\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------------\n",
    "# Modell laden und untersuchen\n",
    "\n",
    "# Load the saved file\n",
    "checkpoint = torch.load('/home/max/Dokumente/CV_projects/RAFT/simple_model.pth')\n",
    "\n",
    "# Create a model object and load the state\n",
    "model = SimpleModel()\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Examine the model structure\n",
    "print(\"Model structure:\")\n",
    "print(model)\n",
    "\n",
    "# Display detailed information about each layer\n",
    "print(\"\\nLayer details:\")\n",
    "for name, layer in model.named_children():\n",
    "    print(f\"Layer {name}: {layer}\")\n",
    "\n",
    "# Generate dummy input data\n",
    "dummy_input = torch.randn(1, 10)\n",
    "\n",
    "# Perform a prediction with the model\n",
    "output = model(dummy_input)\n",
    "\n",
    "# Display input and output shapes\n",
    "print(f\"\\nInput shape: {dummy_input.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "\n",
    "# Optional detailed output for each layer\n",
    "print(\"\\nModule details:\")\n",
    "for name, module in model.named_modules():\n",
    "    print(f\"Module {name}: {module}\")\n",
    "\n",
    "# Optional output of parameters\n",
    "print(\"\\nParameter details:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Parameter {name}: {param.size()}\")\n",
    "\n",
    "# Display parameter details with sizes\n",
    "print(\"\\nParameter details with sizes:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Parameter {name}: {param.size()}, requires_grad: {param.requires_grad}\")\n",
    "    \n",
    "# Display detailed information for each layer with parameters\n",
    "print(\"\\nLayer and parameter details:\")\n",
    "for name, layer in model.named_children():\n",
    "    print(f\"Layer {name}: {layer}\")\n",
    "    for param_name, param in layer.named_parameters(recurse=False):\n",
    "        print(f\"  Param {param_name}: {param.size()}, requires_grad: {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flow estimation on a custom pair of frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimation on a custom pair of frames\n",
    "\n",
    "demo_path = '/home/max/Dokumente/CV_projectsFork/RAFT/custom_demo_frames'\n",
    "frame1 = cv2.imread(os.path.join(demo_path, 'm_baseFrameGray.jpg'))\n",
    "frame2 = cv2.imread(os.path.join(demo_path, 'm_nextFrameGray.jpg'))\n",
    "\n",
    "frame1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2RGB)\n",
    "frame2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "_, ax = plt.subplots(1, 2, figsize=(15, 8))\n",
    "ax[0].imshow(frame1)\n",
    "ax[1].imshow(frame2);\n",
    "\n",
    "## OPTIONAL (use KITTI only model)\n",
    "# del model\n",
    "# model = load_model(\"RAFT/models/raft-kitti.pth\", args=Args())\n",
    "\n",
    "# flow_iters = inference(model, frame1, frame2, device='cuda', pad_mode='kitti', iters=20, test_mode=False)\n",
    "# flow_iters = inference(model, frame1, frame2, device='cuda', pad_mode='kitti', iters=10, test_mode=False)\n",
    "# flow_iters = inference(model, frame1, frame2, device='cuda', pad_mode='kitti', iters=5, test_mode=False)\n",
    "\n",
    "# flow_iters = inference(model, frame1, frame2, device='cuda', pad_mode='kitti', iters=10, test_mode=False)\n",
    "flow_iters = inference(model, frame1, frame2, device='cuda', pad_mode='kitti', iters=10, flow_init=None, upsample=True, test_mode=False)\n",
    "# flow_iters = inference(model, frame1, frame2, device='cuda', pad_mode='kitti', iters=10, flow_init=None, upsample=False, test_mode=False)\n",
    "\n",
    "f, (ax0, ax1) = plt.subplots(1,2, figsize=(15,10))\n",
    "\n",
    "ax0.imshow(get_viz(flow_iters[0]))\n",
    "ax0.set_title('first flow iteration')\n",
    "ax1.imshow(get_viz(flow_iters[-1]))\n",
    "ax1.set_title('final flow iteration');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "raft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
