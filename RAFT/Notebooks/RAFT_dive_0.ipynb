{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **RAFT DIVE**\n",
    "\n",
    "In this notebook we will dive into RAFT, explore how it works, and gain intuition that will allow us to use it with other Advanced Neural Networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add RAFT to core path\n",
    "sys.path.append('RAFT/core')\n",
    "     \n",
    "from raft_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Run RAFT on test images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_path = 'RAFT/demo-frames'\n",
    "frame1 = cv2.imread(os.path.join(demo_path, 'frame_0020.png'))\n",
    "frame2 = cv2.imread(os.path.join(demo_path, 'frame_0021.png'))\n",
    "frame3 = cv2.imread(os.path.join(demo_path, 'frame_0023.png')) # large displacement\n",
    "\n",
    "frame1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2RGB)\n",
    "frame2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2RGB)\n",
    "frame3 = cv2.cvtColor(frame3, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1, 2, figsize=(18, 4))\n",
    "# fig.suptitle(\"Large Displacement\", size=21)\n",
    "# ax[0].imshow(frame1)\n",
    "# ax[0].set_title(\"Frame 20\")\n",
    "# ax[1].imshow(frame2)\n",
    "# ax[1].set_title(\"Frame 23\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = load_model(\"RAFT/models/raft-sintel.pth\", args=Args())\n",
    "\n",
    "# predict Optical Flow\n",
    "flow_iters = inference(model, frame1, frame2, device='cuda', iters=20, test_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, (ax0, ax1) = plt.subplots(1,2, figsize=(20,10))\n",
    "\n",
    "ax0.imshow(get_viz(flow_iters[0]))\n",
    "ax0.set_title('first flow iteration')\n",
    "ax1.imshow(get_viz(flow_iters[-1]))\n",
    "ax1.set_title('final flow iteration');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(25, 5))\n",
    "fig.suptitle(\"Large Displacement\", size=21)\n",
    "ax[0].imshow(frame1)\n",
    "ax[0].set_title(\"Frame 20\", size=18)\n",
    "ax[1].imshow(frame2)\n",
    "ax[1].set_title(\"Frame 23\", size=18)\n",
    "ax[2].imshow(get_viz(flow_iters[-1]))\n",
    "ax[2].set_title(\"Predicted Flow\", size=18);\n",
    "\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get test pixels places of high, low, and medium flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow = flow_iters[-1].squeeze(0).cpu().numpy()\n",
    "abs_flow = np.abs(flow)\n",
    "\n",
    "# highest abs flow in each direction\n",
    "hi_flow_1 = np.where(abs_flow == abs_flow[0, :, :].max()) # u - horizontal\n",
    "hi_flow_2 = np.where(abs_flow == abs_flow[1, :, :].max()) # v - vertical\n",
    "\n",
    "# lowest abs flow in each direction\n",
    "lo_flow_1 = np.where(abs_flow == abs_flow[0, :, :].min()) # u - horizontal\n",
    "lo_flow_2 = np.where(abs_flow == abs_flow[1, :, :].min()) # v - vertical\n",
    "\n",
    "# mean abs flow in each direction\n",
    "me_flow_1 = np.where((abs_flow <= abs_flow[0, :, :].mean() + 1e-4)\n",
    "                     & (abs_flow >= abs_flow[0, :, :].mean() - 1e-4)) \n",
    "me_flow_2 = np.where((abs_flow <= abs_flow[1, :, :].mean() + 1e-4)\n",
    "                     & (abs_flow >= abs_flow[1, :, :].mean() - 1e-4)) \n",
    "\n",
    "\n",
    "lo_flow_1 = np.dstack(lo_flow_1).squeeze()\n",
    "lo_flow_2 = np.dstack(lo_flow_2).squeeze()\n",
    "\n",
    "hi_flow_1 = np.dstack(hi_flow_1).squeeze()\n",
    "hi_flow_2 = np.dstack(hi_flow_2).squeeze()\n",
    "\n",
    "# me_flow_1 = np.dstack(me_flow_1).squeeze()[0]\n",
    "# me_flow_2 = np.dstack(me_flow_2).squeeze()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **RUN Test inference of RAFT**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Test pixel\n",
    "\n",
    "NOTE: For the test pixel we only consider the most extreme horizontal or the most extreme vertical pixel displacements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get test pixel\n",
    "pix = 1\n",
    "# flow_locs = [lo_flow_1, lo_flow_2, hi_flow_1, hi_flow_2]\n",
    "flow_locs = [lo_flow_1, lo_flow_2, hi_flow_2]\n",
    "\n",
    "test_pixel = flow_locs[pix]\n",
    "\n",
    "flow_at_tp = flow_iters[-1].cpu().squeeze(0)[:, test_pixel[1], test_pixel[2]]\n",
    "\n",
    "print(f\"test pixel: {test_pixel} - flow at test pixel: {flow_at_tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTES\n",
    "\n",
    "##### **Regular Displacement**\n",
    " - lo_flow_1 - horizotnal displacement captured by first pyramid level\n",
    " - lo_flow_2 - vertical displacement captured by first pyrmid level\n",
    " - hi_flow_1 \n",
    " - hi_flow_2 - diagonal displacement \n",
    "\n",
    "\n",
    "##### **Large Displacement**\n",
    " - lo_flow_1 - (1.5306e-04, 3.8904e+01) @ (304, 791) large positive vertical displacement (correlation captured in level 0, but radius is too small)\n",
    " - lo_flow_2 - (-1.4967e+01,  1.3452e-05) @ (156, 102) large negative horizontal displacement \n",
    " - hi_flow_1 -  (34.0357, -18.9150) @ (248, 498) seems to be captured by the 3rd level, amybe the first level as well?\n",
    " - hi_flow_2 - (4.7941, 44.7952) @ (329, 952) strongly captured by second level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict Optical Flow\n",
    "model_outputs = test_inference(model, frame1, frame2, device='cuda', iters=20, test_pixel=test_pixel, test_mode=True)\n",
    "features, test_responses, motion_features, hidden_states, flow_low, flow_up = model_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "\n",
    "flow_viz = get_viz(flow_up)\n",
    "\n",
    "\n",
    "_, ax = plt.subplots(1, 1, figsize=(10, 4))\n",
    "\n",
    "\n",
    "colors = ['r', 'k', 'c']\n",
    "for i, (c, loc) in enumerate(zip(colors, flow_locs)):\n",
    "    rect = patches.Rectangle(loc[1:][::-1] - 5.5, 6, 6, linewidth=2, edgecolor=c, facecolor=c, label=f\"pixel {i}\")\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "    flow_viz = cv2.putText(flow_viz, f\"pixel {i}\", loc[1:][::-1] - np.array([40, 20]), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    # get flow at test pixel\n",
    "    flow = flow_iters[-1].cpu().squeeze(0)[:, loc[1], loc[2]]\n",
    "\n",
    "\n",
    "\n",
    "ax.imshow(flow_viz)\n",
    "\n",
    "ax.set_title(\"Test Pixel locations\");\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Inspect Feature Maps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmap1, fmap2, hiddn, cntxt = features\n",
    "\n",
    "fmap1 = fmap1.squeeze(0).cpu().numpy()\n",
    "fmap2 = fmap2.squeeze(0).cpu().numpy()\n",
    "hiddn = hiddn.squeeze(0).cpu().numpy()\n",
    "cntxt = cntxt.squeeze(0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmap1.shape, fmap2.shape, hiddn.shape, cntxt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 100\n",
    "\n",
    "# for i in range(128):\n",
    "#     fig, ax = plt.subplots(2, 2, figsize=(12, 6))\n",
    "\n",
    "#     fig.suptitle(f\"Extracted Feature Maps - {i}\")\n",
    "#     ax[0][0].imshow(fmap1[i, :, :])\n",
    "#     ax[0][0].set_title(\"fmap 1\")\n",
    "\n",
    "#     ax[0][1].imshow(fmap2[i, :, :])\n",
    "#     ax[0][1].set_title(\"fmap 2\")\n",
    "\n",
    "#     ax[1][0].imshow(hiddn[i, :, :])\n",
    "#     ax[1][0].set_title(\"Hidden\")\n",
    "\n",
    "#     ax[1][1].imshow(cntxt[i, :, :])\n",
    "#     ax[1][1].set_title(\"Context\");\n",
    "\n",
    "#     fig.savefig(f\"C:\\\\Users\\\\itber\\\\Documents\\\\utils\\\\gif_maker\\\\frames_5\\\\feature_{i}.png\")\n",
    "#     plt.close();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Print relative pixel motion at each pyramid level**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    # print(test_responses[0][i][2], test_responses[9][i][2], test_responses[0][i][2] - test_responses[9][i][2])\n",
    "    print(f\"Pixel Motion at level: {i}: {test_responses[0][i][2] - test_responses[9][i][2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pyramid level that captures most of the correspondence information is the level that captures the most displacement. Multiplying the pixel motion at level 0 gives us an approximate flow estimate. Since the current flow estimate is used to find the correspodences in the correlation volumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itr = 9 # iterations\n",
    "pyramid_flow = 8*(test_responses[0][0][2] - test_responses[itr][0][2])\n",
    "pyramid_flow = 8*2*(test_responses[0][1][2] - test_responses[itr][1][2])\n",
    "\n",
    "print(f\"predicted: {flow_at_tp} - flow at pyramid level 0: {pyramid_flow}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Inspect Test Responses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itr = 0\n",
    "lvl = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display correlation response at Test Pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pixel location\n",
    "pixel_loc = test_responses[itr][lvl][2]\n",
    "pixel_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 5))\n",
    "\n",
    "ax.imshow(test_responses[itr][lvl][0]);\n",
    "ax.set_title(f\"Pixel {pix} Correlation Response \\n \"\n",
    "             + f\"Iter: {itr} - Level: {lvl} - Pixel: {test_pixel[1:]} - Correspondance: {pixel_loc.round(2)[::-1]}\");\n",
    "\n",
    "# mark I2 pixel under test\n",
    "rect = patches.Rectangle(pixel_loc - 0.5, 1, 1, linewidth=2, edgecolor='r', facecolor='none')\n",
    "# rect = patches.Rectangle(pixel_loc - (0.5/(2**lvl)), 1, 1, linewidth=2, edgecolor='r', facecolor='none')\n",
    "ax.add_patch(rect)\n",
    "\n",
    "# TEMP: draw arrow for display\n",
    "# plt.arrow(pixel_loc.astype(int)[0] + 3, pixel_loc.astype(int)[1] + 2, -4, 0, linewidth=2, head_width=1, edgecolor='r', facecolor='r') # p0\n",
    "# plt.arrow(pixel_loc.astype(int)[0] - 2, pixel_loc.astype(int)[1] - 3, 0, 3, linewidth=2, head_width=1, edgecolor='r', facecolor='r') # p1\n",
    "# plt.arrow(pixel_loc.astype(int)[0] - 3, pixel_loc.astype(int)[1] - 0, 0, 3, linewidth=2, head_width=1, edgecolor='r', facecolor='r') # p2\n",
    "\n",
    "\n",
    "plt.show();\n",
    "# fig.savefig(f\"C:\\\\Users\\\\itber\\\\Documents\\\\utils\\\\gif_maker\\\\frames_1\\\\pixel2_iter{itr}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Zoomed pixel location and Resampled Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 4\n",
    "u = slice(int(pixel_loc[0] - r), int(pixel_loc[0] + r + 1)) # horizontal\n",
    "v = slice(int(pixel_loc[1] - r), int(pixel_loc[1] + r + 1)) # vertical\n",
    "\n",
    "u = slice(int(np.clip(pixel_loc[0] - r, 0, np.infty)), int(np.clip(pixel_loc[0] + r + 1, 0, np.infty)))\n",
    "v = slice(int(np.clip(pixel_loc[1] - r, 0, np.infty)), int(np.clip(pixel_loc[1] + r + 1, 0, np.infty)))\n",
    "\n",
    "zoomed_response = test_responses[itr][lvl][0][v, u]\n",
    "bilres_response = test_responses[itr][lvl][1].T\n",
    "\n",
    "## NEEDS UPDATE FOR ALL CASES \n",
    "# add zero padding for display\n",
    "delta = zoomed_response.shape[0] - zoomed_response.shape[1]\n",
    "\n",
    "if delta < 0:\n",
    "    zoomed_response = np.vstack(( zoomed_response, np.zeros((abs(delta), (2*r) + 1)) ))\n",
    "# FILL IN REST OF CASES HERE\n",
    "\n",
    "# rescale for consistent visibility\n",
    "zoomed_response = cv2.normalize(zoomed_response, dst=None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "bilres_response = cv2.normalize(bilres_response, dst=None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax[0].imshow(zoomed_response);\n",
    "ax[0].set_title(f\"Pixel {pix} Correlation Response ZOOM \\n \"\n",
    "             + f\"Iter: {itr} - Level: {lvl} - Pixel: {test_pixel[1:]} - Correspondance: {pixel_loc.round(2)[::-1]}\");\n",
    "# mark I2 pixel under test\n",
    "rect = patches.Rectangle((r + (pixel_loc % 1) - 0.5), 1, 1, linewidth=2, edgecolor='r', facecolor='none')\n",
    "ax[0].add_patch(rect)\n",
    "\n",
    "\n",
    "ax[1].imshow(bilres_response);\n",
    "ax[1].set_title(f\"Pixel {pix} Bilinearly Resampled Correlation Response \\n \"\n",
    "             + f\"Iter: {itr} - Level: {lvl} - Pixel: {test_pixel[1:]} - Correspondance: {pixel_loc.round(2)[::-1]}\");\n",
    "\n",
    "# mark I2 pixel under test\n",
    "rect = patches.Rectangle((3.5, 3.5), 1, 1, linewidth=2, edgecolor='r', facecolor='none')\n",
    "ax[1].add_patch(rect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At iteration 1, the bilinear resampling should be the same since there is no optical flow. (Unless we warm start with previous flow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Inspect the Motion Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_features[itr].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_feats = motion_features[itr].squeeze(0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    m_feats = motion_features[i].squeeze(0).cpu().numpy()\n",
    "\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(12, 6))\n",
    "    fig.suptitle(f\"Motion Features - Iter: {i}\", size=18, weight=10);\n",
    "    ax[0][0].imshow(m_feats[11, :, :])\n",
    "    ax[0][0].set_title(\"Motion Feature: 11\")\n",
    "\n",
    "    ax[0][1].imshow(m_feats[68, :, :])\n",
    "    ax[0][1].set_title(\"Motion Feature: 68\")\n",
    "\n",
    "    ax[1][0].imshow(m_feats[98, :, :])\n",
    "    ax[1][0].set_title(\"Motion Feature: 98\")\n",
    "\n",
    "    ax[1][1].imshow(m_feats[100, :, :])\n",
    "    ax[1][1].set_title(\"Motion Feature: 100\");\n",
    "\n",
    "    fig.savefig(f\"C:\\\\Users\\\\itber\\\\Documents\\\\utils\\\\gif_maker\\\\frames_4\\\\motion_feats_iter_0000{i}\");\n",
    "    plt.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_feats = motion_features[0].squeeze(0).cpu().numpy()\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(12, 6))\n",
    "ax[0][0].imshow(m_feats[11, :, :])\n",
    "ax[0][0].set_title(\"Motion Feature: 0\")\n",
    "\n",
    "ax[0][1].imshow(m_feats[10, :, :])\n",
    "ax[0][1].set_title(\"Motion Feature: 10\")\n",
    "\n",
    "ax[1][0].imshow(m_feats[50, :, :])\n",
    "ax[1][0].set_title(\"Motion Feature: 50\")\n",
    "\n",
    "ax[1][1].imshow(m_feats[100, :, :])\n",
    "ax[1][1].set_title(\"Motion Feature: 100\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Inspect the hidden states**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hid_states = hidden_states[0].squeeze(0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(12, 6))\n",
    "ax[0][0].imshow(hid_states[0, :, :])\n",
    "ax[0][0].set_title(\"Hidden State: 0\")\n",
    "\n",
    "ax[0][1].imshow(hid_states[10, :, :])\n",
    "ax[0][1].set_title(\"Hidden State: 10\")\n",
    "\n",
    "ax[1][0].imshow(hid_states[50, :, :])\n",
    "ax[1][0].set_title(\"Hidden State: 50\")\n",
    "\n",
    "ax[1][1].imshow(hid_states[100, :, :])\n",
    "ax[1][1].set_title(\"Hidden State: 100\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "\n",
    "    # plt.figure(figsize=(8, 4))\n",
    "    # plt.imshow(hid_states[i, :, :])\n",
    "    # plt.title(f\"Hidden State: {i}\")\n",
    "\n",
    "    h_states = hidden_states[i].squeeze(0).cpu().numpy()\n",
    "\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(12, 6))\n",
    "    ax[0][0].imshow(h_states[0, :, :])\n",
    "    ax[0][0].set_title(f\"Hidden State: 0 - iter: {i}\")\n",
    "\n",
    "    ax[0][1].imshow(h_states[10, :, :])\n",
    "    ax[0][1].set_title(f\"Hidden State: 10 - iter: {i}\")\n",
    "\n",
    "    ax[1][0].imshow(h_states[50, :, :])\n",
    "    ax[1][0].set_title(f\"Hidden State: 50 - iter: {i}\")\n",
    "\n",
    "    ax[1][1].imshow(h_states[100, :, :])\n",
    "    ax[1][1].set_title(f\"Hidden State: 100 - iter: {i}\");\n",
    "\n",
    "    fig.savefig(f\"C:\\\\Users\\\\itber\\\\Documents\\\\utils\\\\gif_maker\\\\frames_6\\\\hidden_state_{i}\");\n",
    "    plt.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.imshow(hid_states[i, :, :])\n",
    "plt.title(f\"Hidden State: {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
