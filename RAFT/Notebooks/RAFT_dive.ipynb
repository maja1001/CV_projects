{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **RAFT DIVE**\n",
    "\n",
    "In this notebook we will dive into RAFT, explore how it works, and gain intuition that will allow us to use it with other Advanced Neural Networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add RAFT to core path\n",
    "sys.path.append('RAFT/core')\n",
    "     \n",
    "from raft_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set savepath for GIFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GIF_SAVEPATH = r\"C:\\Users\\itber\\Documents\\utils\\gif_maker\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Run RAFT on test images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame1 = cv2.imread('test_images/fan_frame_1.png')\n",
    "frame2 = cv2.imread('test_images/fan_frame_2.png')\n",
    "frame3 = cv2.imread('test_images/fan_frame_3.png') # large displacement\n",
    "\n",
    "# frame1 = cv2.imread('test_images/fan_frame_61.png')\n",
    "# frame2 = cv2.imread('test_images/fan_frame_62.png')\n",
    "# frame3 = cv2.imread('test_images/fan_frame_63.png') # large displacement\n",
    "\n",
    "frame1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2RGB)\n",
    "frame2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2RGB)\n",
    "frame3 = cv2.cvtColor(frame3, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1, 2, figsize=(18, 4))\n",
    "# fig.suptitle(\"Large Displacement\", size=21)\n",
    "# ax[0].imshow(frame1)\n",
    "# ax[0].set_title(\"Frame 20\")\n",
    "# ax[1].imshow(frame2)\n",
    "# ax[1].set_title(\"Frame 23\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = load_model(\"RAFT/models/raft-sintel.pth\", args=Args())\n",
    "\n",
    "# predict Optical Flow\n",
    "flow_iters = inference(model, frame1, frame3, device='cuda', iters=20, test_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, (ax0, ax1) = plt.subplots(1,2, figsize=(20,10))\n",
    "\n",
    "ax0.imshow(get_viz(flow_iters[0]))\n",
    "ax0.set_title('first flow iteration')\n",
    "ax1.imshow(get_viz(flow_iters[-1]))\n",
    "ax1.set_title('final flow iteration');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(25, 6))\n",
    "fig.suptitle(\"Large Displacement\", size=21)\n",
    "ax[0].imshow(frame1)\n",
    "ax[0].set_title(\"Frame 1\", size=18)\n",
    "ax[1].imshow(frame3)\n",
    "ax[1].set_title(\"Frame 3\", size=18)\n",
    "ax[2].imshow(get_viz(flow_iters[-1]))\n",
    "ax[2].set_title(\"Predicted Flow\", size=18);\n",
    "\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get test pixels places of high, low, and medium flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow = flow_iters[-1].squeeze(0).cpu().numpy()\n",
    "abs_flow = np.abs(flow)\n",
    "\n",
    "# highest abs flow in each direction\n",
    "hi_flow_1 = np.where(abs_flow == abs_flow[0, :, :].max()) # u - horizontal\n",
    "hi_flow_2 = np.where(abs_flow == abs_flow[1, :, :].max()) # v - vertical\n",
    "\n",
    "# lowest abs flow in each direction\n",
    "lo_flow_1 = np.where(abs_flow == abs_flow[0, :, :].min()) # u - horizontal\n",
    "lo_flow_2 = np.where(abs_flow == abs_flow[1, :, :].min()) # v - vertical\n",
    "\n",
    "# mean abs flow in each direction\n",
    "me_flow_1 = np.where((abs_flow <= abs_flow[0, :, :].mean() + 1e-4)\n",
    "                     & (abs_flow >= abs_flow[0, :, :].mean() - 1e-4)) \n",
    "me_flow_2 = np.where((abs_flow <= abs_flow[1, :, :].mean() + 1e-4)\n",
    "                     & (abs_flow >= abs_flow[1, :, :].mean() - 1e-4)) \n",
    "\n",
    "\n",
    "lo_flow_1 = np.dstack(lo_flow_1).squeeze()\n",
    "lo_flow_2 = np.dstack(lo_flow_2).squeeze()\n",
    "\n",
    "hi_flow_1 = np.dstack(hi_flow_1).squeeze()\n",
    "hi_flow_2 = np.dstack(hi_flow_2).squeeze()\n",
    "\n",
    "# me_flow_1 = np.dstack(me_flow_1).squeeze()[0]\n",
    "# me_flow_2 = np.dstack(me_flow_2).squeeze()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "me_flow_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "me_flow_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **RUN Test inference of RAFT**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Test pixel\n",
    "\n",
    "NOTE: For the test pixel we only consider the most extreme horizontal or the most extreme vertical pixel displacements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "320/8, 568/8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Test Pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_locs = [hi_flow_1, hi_flow_2, np.array([0, 175, 405])]\n",
    "\n",
    "\n",
    "flow_locs = [np.array([0, 60, 260]), # with frame 2, this has multiple descent directions and chooses the closest one!\n",
    "             np.array([0, 175, 405]),\n",
    "             np.array([0, 275, 315])\n",
    "             # np.array([0, 270, 320])\n",
    "            # np.array([0, 173, 215])\n",
    "             ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Test Pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get test pixel\n",
    "pix = 0\n",
    "\n",
    "test_pixel = flow_locs[pix]\n",
    "\n",
    "flow_at_tp = flow_iters[-1].cpu().squeeze(0)[:, test_pixel[1], test_pixel[2]]\n",
    "\n",
    "print(f\"test pixel: {test_pixel} - flow at test pixel: {flow_at_tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display All test pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict Optical Flow\n",
    "model_outputs = test_inference(model, frame1, frame3, device='cuda', iters=20, test_pixel=test_pixel, test_mode=True)\n",
    "features, test_responses, motion_features, hidden_states, flow_low, flow_up = model_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "\n",
    "flow_viz = get_viz(flow_up)\n",
    "\n",
    "\n",
    "_, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "\n",
    "\n",
    "colors = ['r', 'k', 'c', 'b']\n",
    "for i, (c, loc) in enumerate(zip(colors, flow_locs)):\n",
    "    rect = patches.Rectangle(loc[1:][::-1] - 5.5, 6, 6, linewidth=2, edgecolor=c, facecolor=c, label=f\"pixel {i}\")\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "    flow_viz = cv2.putText(flow_viz, f\"pixel {i}\", loc[1:][::-1] - np.array([40, 20]), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    # get flow at test pixel\n",
    "    flow = flow_iters[-1].cpu().squeeze(0)[:, loc[1], loc[2]]\n",
    "\n",
    "\n",
    "\n",
    "ax.imshow(flow_viz)\n",
    "\n",
    "ax.set_title(\"Test Pixel locations\");\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Inspect Feature Maps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmap1, fmap2, hiddn, cntxt = features\n",
    "\n",
    "fmap1 = fmap1.squeeze(0).cpu().numpy()\n",
    "fmap2 = fmap2.squeeze(0).cpu().numpy()\n",
    "hiddn = hiddn.squeeze(0).cpu().numpy()\n",
    "cntxt = cntxt.squeeze(0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmap1.shape, fmap2.shape, hiddn.shape, cntxt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(128):\n",
    "\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    fig.suptitle(f\"Extracted Feature maps - Iter: {i}\", size=18, weight=10);\n",
    "    ax[0][0].imshow(fmap1[i, :, :])\n",
    "    ax[0][0].set_title(\"fmap 1\")\n",
    "\n",
    "    ax[0][1].imshow(fmap2[i, :, :])\n",
    "    ax[0][1].set_title(\"fmap 2\")\n",
    "\n",
    "    ax[1][0].imshow(hiddn[i, :, :])\n",
    "    ax[1][0].set_title(\"Hidden\")\n",
    "\n",
    "    ax[1][1].imshow(cntxt[i, :, :])\n",
    "    ax[1][1].set_title(\"Context\");\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    \n",
    "    fig.savefig(os.path.join(GIF_SAVEPATH, f\"extracted_features\\\\extracted_features_iter_0000{i}\"));\n",
    "    plt.close();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Inspect Test Responses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itr = 0\n",
    "lvl = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display correlation response at Test Pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pixel location\n",
    "pixel_loc = test_responses[itr][lvl][2]\n",
    "pixel_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20, 10))\n",
    "\n",
    "ax.imshow(test_responses[itr][lvl][0]);\n",
    "ax.set_title(f\"Pixel {pix} Correlation Response \\n \"\n",
    "             + f\"Iter: {itr} - Level: {lvl} - Pixel: {test_pixel[1:]} - Correspondance: {pixel_loc.round(2)[::-1]}\");\n",
    "\n",
    "# mark I2 pixel under test\n",
    "rect = patches.Rectangle(pixel_loc - 0.5, 1, 1, linewidth=2, edgecolor='r', facecolor='none')\n",
    "# rect = patches.Rectangle(pixel_loc - (0.5/(2**lvl)), 1, 1, linewidth=2, edgecolor='r', facecolor='none')\n",
    "ax.add_patch(rect)\n",
    "\n",
    "# TEMP: draw arrow for display\n",
    "# plt.arrow(pixel_loc.astype(int)[0] - 1, pixel_loc.astype(int)[1] + 2, 4, 0, linewidth=2, head_width=1, edgecolor='r', facecolor='r') # p0\n",
    "# plt.arrow(pixel_loc.astype(int)[0] - 3, pixel_loc.astype(int)[1] + 2, 0, -3, linewidth=2, head_width=1, edgecolor='r', facecolor='r') # p1\n",
    "# plt.arrow(pixel_loc.astype(int)[0] - 3, pixel_loc.astype(int)[1] - 0, 0, 3, linewidth=2, head_width=1, edgecolor='r', facecolor='r') # p2\n",
    "\n",
    "\n",
    "plt.show();\n",
    "# fig.savefig(f\"C:\\\\Users\\\\itber\\\\Documents\\\\utils\\\\gif_maker\\pixel{pix}\\\\pixel_lvl{lvl}_iter{itr}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Zoomed pixel location and Resampled Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 4\n",
    "u = slice(int(pixel_loc[0] - r), int(pixel_loc[0] + r + 1)) # horizontal\n",
    "v = slice(int(pixel_loc[1] - r), int(pixel_loc[1] + r + 1)) # vertical\n",
    "\n",
    "u = slice(int(np.clip(pixel_loc[0] - r, 0, np.infty)), int(np.clip(pixel_loc[0] + r + 1, 0, np.infty)))\n",
    "v = slice(int(np.clip(pixel_loc[1] - r, 0, np.infty)), int(np.clip(pixel_loc[1] + r + 1, 0, np.infty)))\n",
    "\n",
    "zoomed_response = test_responses[itr][lvl][0][v, u]\n",
    "bilres_response = test_responses[itr][lvl][1].T\n",
    "\n",
    "## NEEDS UPDATE FOR ALL CASES \n",
    "# add zero padding for display\n",
    "delta = zoomed_response.shape[0] - zoomed_response.shape[1]\n",
    "\n",
    "if delta < 0:\n",
    "    zoomed_response = np.vstack(( zoomed_response, np.zeros((abs(delta), (2*r) + 1)) ))\n",
    "# FILL IN REST OF CASES HERE\n",
    "\n",
    "# rescale for consistent visibility\n",
    "zoomed_response = cv2.normalize(zoomed_response, dst=None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "bilres_response = cv2.normalize(bilres_response, dst=None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax[0].imshow(zoomed_response);\n",
    "ax[0].set_title(f\"Pixel {pix} Correlation Response ZOOM \\n \"\n",
    "             + f\"Iter: {itr} - Level: {lvl} - Pixel: {test_pixel[1:]} - Correspondance: {pixel_loc.round(2)[::-1]}\");\n",
    "# mark I2 pixel under test\n",
    "rect = patches.Rectangle((r + (pixel_loc % 1) - 0.5), 1, 1, linewidth=2, edgecolor='r', facecolor='none')\n",
    "ax[0].add_patch(rect)\n",
    "\n",
    "\n",
    "ax[1].imshow(bilres_response);\n",
    "ax[1].set_title(f\"Pixel {pix} Bilinearly Resampled Correlation Response \\n \"\n",
    "             + f\"Iter: {itr} - Level: {lvl} - Pixel: {test_pixel[1:]} - Correspondance: {pixel_loc.round(2)[::-1]}\");\n",
    "\n",
    "# mark I2 pixel under test\n",
    "rect = patches.Rectangle((3.5, 3.5), 1, 1, linewidth=2, edgecolor='r', facecolor='none')\n",
    "ax[1].add_patch(rect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(zoomed_response, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At iteration 1, the bilinear resampling should be the same since there is no optical flow. (Unless we warm start with previous flow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Inspect the Motion Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_features[itr].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_feats = motion_features[itr].squeeze(0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    m_feats = motion_features[i].squeeze(0).cpu().numpy()\n",
    "    \n",
    "    fig, ax = plt.subplots(2, 3, figsize=(16, 7))\n",
    "    fig.suptitle(f\"Motion Features - Iter: {i}\", size=18, weight=10);\n",
    "    ax[0][0].imshow(m_feats[20, :, :])\n",
    "    ax[0][0].set_title(\"Motion Feature: 20\")\n",
    "\n",
    "    ax[1][0].imshow(m_feats[48, :, :])\n",
    "    ax[1][0].set_title(\"Motion Feature: 48\")\n",
    "\n",
    "    ax[0][1].imshow(m_feats[49, :, :])\n",
    "    ax[0][1].set_title(\"Motion Feature: 49\")\n",
    "\n",
    "    ax[1][1].imshow(m_feats[121, :, :])\n",
    "    ax[1][1].set_title(\"Motion Feature: 121\")\n",
    "\n",
    "    ax[0][2].imshow(m_feats[126, :, :])\n",
    "    ax[0][2].set_title(\"Motion Feature: 126\")\n",
    "\n",
    "    ax[1][2].imshow(m_feats[127, :, :])\n",
    "    ax[1][2].set_title(\"Motion Feature: 127\");\n",
    "\n",
    "    plt.tight_layout();\n",
    "\n",
    "\n",
    "    fig.savefig(os.path.join(GIF_SAVEPATH, r\"motion_features\\\\motion_feats_iter_0000{i}\"));\n",
    "    plt.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_feats = motion_features[15].squeeze(0).cpu().numpy()\n",
    "\n",
    "fig, ax = plt.subplots(2, 3, figsize=(14, 6))\n",
    "ax[0][0].imshow(m_feats[20, :, :])\n",
    "ax[0][0].set_title(\"Motion Feature: 20\")\n",
    "\n",
    "ax[1][0].imshow(m_feats[48, :, :])\n",
    "ax[1][0].set_title(\"Motion Feature: 48\")\n",
    "\n",
    "ax[0][1].imshow(m_feats[49, :, :])\n",
    "ax[0][1].set_title(\"Motion Feature: 49\")\n",
    "\n",
    "ax[1][1].imshow(m_feats[121, :, :])\n",
    "ax[1][1].set_title(\"Motion Feature: 121\")\n",
    "\n",
    "ax[0][2].imshow(m_feats[126, :, :])\n",
    "ax[0][2].set_title(\"Motion Feature: 126\")\n",
    "\n",
    "ax[1][2].imshow(m_feats[127, :, :])\n",
    "ax[1][2].set_title(\"Motion Feature: 127\");\n",
    "\n",
    "plt.tight_layout();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(20):\n",
    "#     m_feats = motion_features[i].squeeze(0).cpu().numpy()\n",
    "\n",
    "#     for j in range(m_feats.shape[0]):\n",
    "#         fig = plt.figure(figsize=(20, 10))\n",
    "#         plt.imshow(m_feats[j, :, :])\n",
    "#         plt.title(f\"Motion Feature: {j} - Iteration - {i}\")\n",
    "\n",
    "#         fig.savefig(f\"C:\\\\Users\\\\itber\\\\Documents\\\\utils\\\\gif_maker\\\\motion_features\\\\motion_feats_iter_0000{i}_{j}\");\n",
    "#         plt.close();\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Inspect the hidden states**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hid_states = hidden_states[0].squeeze(0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(12, 6))\n",
    "ax[0][0].imshow(hid_states[0, :, :])\n",
    "ax[0][0].set_title(\"Hidden State: 0\")\n",
    "\n",
    "ax[0][1].imshow(hid_states[10, :, :])\n",
    "ax[0][1].set_title(\"Hidden State: 10\")\n",
    "\n",
    "ax[1][0].imshow(hid_states[50, :, :])\n",
    "ax[1][0].set_title(\"Hidden State: 50\")\n",
    "\n",
    "ax[1][1].imshow(hid_states[100, :, :])\n",
    "ax[1][1].set_title(\"Hidden State: 100\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "\n",
    "    # plt.figure(figsize=(8, 4))\n",
    "    # plt.imshow(hid_states[i, :, :])\n",
    "    # plt.title(f\"Hidden State: {i}\")\n",
    "\n",
    "    h_states = hidden_states[i].squeeze(0).cpu().numpy()\n",
    "\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(12, 6))\n",
    "    ax[0][0].imshow(h_states[0, :, :])\n",
    "    ax[0][0].set_title(f\"Hidden State: 0 - iter: {i}\")\n",
    "\n",
    "    ax[0][1].imshow(h_states[10, :, :])\n",
    "    ax[0][1].set_title(f\"Hidden State: 10 - iter: {i}\")\n",
    "\n",
    "    ax[1][0].imshow(h_states[50, :, :])\n",
    "    ax[1][0].set_title(f\"Hidden State: 50 - iter: {i}\")\n",
    "\n",
    "    ax[1][1].imshow(h_states[100, :, :])\n",
    "    ax[1][1].set_title(f\"Hidden State: 100 - iter: {i}\");\n",
    "\n",
    "\n",
    "    fig.savefig(os.path.join(GIF_SAVEPATH, r\"frames_6\\\\hidden_state_{i}\"));\n",
    "    plt.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.imshow(hid_states[i, :, :])\n",
    "plt.title(f\"Hidden State: {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
